{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f882809-621c-43df-8540-6a949e2633cc",
   "metadata": {},
   "source": [
    "## Top Repositories on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde13f94-e4d6-4640-9824-cfa64bdca00f",
   "metadata": {},
   "source": [
    "## Problem Statement:\n",
    "\n",
    "GitHub is a widely-used platform for sharing and discovering open-source projects. The platform organizes repositories into various topics, making it easier to explore related projects. However, GitHub does not provide a direct, structured dataset for these topics and their associated repositories. This project aims to automate the extraction of relevant data from the GitHub Topics page , allowing users to analyze and explore repositories based on different topics. By scraping this data, we can create CSV files that include key repository details such as name, author, stars, and URL for each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6966c843-2ed7-4ac9-9831-bab8f1a14d4f",
   "metadata": {},
   "source": [
    "## Project Outline:\n",
    "\n",
    "1. We're going to scrape https://github.com/topics\n",
    "2. We'll get a list of topics. For each topic we'll get topic title, page url and description\n",
    "3. For each topic, we'll get the top repositories on the topic from the topic page\n",
    "4. For each repository, we'll grab the repo name, username,stars and repo URl\n",
    "5. For each topic we'll create a CSV file in the following format:\n",
    "\n",
    "Repo name,Username,Stars,Repo URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fce9b-4bf1-4959-82a1-3fdbd6356ef7",
   "metadata": {},
   "source": [
    "## Tools used:\n",
    "\n",
    "1. Python\n",
    "2. requests\n",
    "3. Beautiful Soup\n",
    "4. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9b666-c458-45e2-9188-3f1e8264ca93",
   "metadata": {},
   "source": [
    "## Scrape list of topics from GitHub\n",
    "\n",
    "- use requests to download the page\n",
    "- use BS4 to parse and extract info\n",
    "- convert to a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d51fd302-7b2c-497a-bc72-b4885bf3048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e34e2-ec47-42e2-997c-fd0303f46e0d",
   "metadata": {},
   "source": [
    "This function takes the URL of a specific topic (e.g., \"Awesome Lists\") and returns its HTML document, which contains repository details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d31612-761c-48e9-9976-ceed5fda154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to download page\n",
    "def get_topic_page():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topics_url))\n",
    "\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7db5227-e68f-477c-a73d-9a78ff036f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_topic_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c8924e-4f59-4987-8563-acc474ac10f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4c8e620-9770-4197-803e-c91a3466a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"px-2 py-4 color-bg-accent-emphasis color-fg-on-emphasis show-on-focus js-skip-to-content\" data-skip-target-assigned=\"false\" href=\"#start-of-content\">Skip to content</a>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc3ffd-1371-42c7-a3fc-fc3163475939",
   "metadata": {},
   "source": [
    "## helper function to parse info from page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8b04e6-929f-4b39-a55d-4328d239402a",
   "metadata": {},
   "source": [
    "To get topic titles, we can pick `p` tags with the `class`...\n",
    "![](IMG/title.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686cdf6-e24f-46b7-972c-29af88836059",
   "metadata": {},
   "source": [
    "Extracts all topic titles (like \"Awesome Lists\") from the main topics page and returns them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c226a5c-80f8-4fcc-afbd-a90e29450206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get list of titles\n",
    "def get_topic_titles(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tags = doc.find_all('p', {'class': selection_class})\n",
    "    topic_titles = []\n",
    "    for tag in topic_title_tags:\n",
    "        topic_titles.append(tag.text.strip())\n",
    "    return topic_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f59a9f76-c74b-4ed3-afd6-30c1e894cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_topic_titles(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "473b4ef8-774a-41e0-86e5-6de5b915c441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Awesome Lists',\n",
       " 'Chrome',\n",
       " 'Code quality',\n",
       " 'Compiler',\n",
       " 'CSS',\n",
       " 'Database',\n",
       " 'Front end',\n",
       " 'JavaScript',\n",
       " 'Node.js',\n",
       " 'npm',\n",
       " 'Project management',\n",
       " 'Python',\n",
       " 'React',\n",
       " 'React Native',\n",
       " 'Scala',\n",
       " 'TypeScript']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc419ff-bd05-4628-95db-f4e3482000f6",
   "metadata": {},
   "source": [
    "To get topic titles, we can pick `p` tags with the `class`...\n",
    "![](IMG/description.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07ce14-7252-419a-b1fb-afd37b38a9b1",
   "metadata": {},
   "source": [
    "Extracts all topic descriptions (short summary text under each topic) and returns them as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c16c99d-ffc1-44bc-a2ff-17d7a438f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get description\n",
    "def get_topic_descs(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tags = doc.find_all('p', {'class': desc_selector})\n",
    "    topic_descs = []\n",
    "    for tag in topic_desc_tags:\n",
    "        topic_descs.append(tag.text.strip())\n",
    "    return topic_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d6db70c-30c6-4511-b581-e45853cf7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = get_topic_descs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29f08bfa-eb29-42d7-a24f-880bb3dc7c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An awesome list is a list of awesome things curated by the community.',\n",
       " 'Chrome is a web browser from the tech company Google.',\n",
       " 'Automate your code review with style, quality, security, and testâ€‘coverage checks when you need them.',\n",
       " 'Compilers are software that translate higher-level programming languages to lower-level languages (e.g. machine code).',\n",
       " 'Cascading Style Sheets (CSS) is a language used most often to style and improve upon the appearance of views.',\n",
       " 'A database is a structured set of data held in a computer, usually a server.',\n",
       " 'Front end is the programming and layout that people see and interact with.',\n",
       " 'JavaScript (JS) is a lightweight interpreted programming language with first-class functions.',\n",
       " 'Node.js is a tool for executing JavaScript in a variety of environments.',\n",
       " 'npm is a package manager for JavaScript included with Node.js.',\n",
       " \"Project management is about building scope and executing on the project's goals.\",\n",
       " 'Python is a dynamically typed programming language.',\n",
       " 'React is an open source JavaScript library used for designing user interfaces.',\n",
       " 'React Native is a JavaScript mobile framework developed by Facebook.',\n",
       " 'Scala is an object-oriented programming language.',\n",
       " 'TypeScript is a typed superset of JavaScript that compiles to plain JavaScript.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8110af01-cf8a-4a0c-9fc0-a38daa88bcd4",
   "metadata": {},
   "source": [
    "To get topic titles, we can pick `p` tags with the `class`...\n",
    "![](IMG/url.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c066fa83-ee16-4f91-945c-0a555abad8bd",
   "metadata": {},
   "source": [
    "Collects the URLs of all topics (e.g., /topics/awesome) and appends the base GitHub URL, returning a list of full topic links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d66c0f32-4069-45b8-9a99-9918bca5e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get repo link\n",
    "def get_topic_urls(doc):\n",
    "    topic_urls = []\n",
    "    base_url = 'https://github.com'\n",
    "    topic_link_tags = doc.find_all('a', {'class': 'no-underline flex-1 d-flex flex-column'})\n",
    "    for tag in topic_link_tags:\n",
    "        topic_urls.append(base_url + tag['href'])\n",
    "    return topic_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06310aed-3598-41dd-8087-3c0f8db0f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = get_topic_urls(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0482de5a-7d18-472c-9748-c9aad2fbe752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/topics/awesome',\n",
       " 'https://github.com/topics/chrome',\n",
       " 'https://github.com/topics/code-quality',\n",
       " 'https://github.com/topics/compiler',\n",
       " 'https://github.com/topics/css',\n",
       " 'https://github.com/topics/database',\n",
       " 'https://github.com/topics/frontend',\n",
       " 'https://github.com/topics/javascript',\n",
       " 'https://github.com/topics/nodejs',\n",
       " 'https://github.com/topics/npm',\n",
       " 'https://github.com/topics/project-management',\n",
       " 'https://github.com/topics/python',\n",
       " 'https://github.com/topics/react',\n",
       " 'https://github.com/topics/react-native',\n",
       " 'https://github.com/topics/scala',\n",
       " 'https://github.com/topics/typescript']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f66c07-16d9-4cb4-ac5c-191c90778a92",
   "metadata": {},
   "source": [
    "This function downloads the main GitHub Topics page (https://github.com/topics) and parses it with BeautifulSoup, returning the HTML document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a09ebe45-9a13-463b-8327-5ecb3c3add57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_page():\n",
    "    topics_url = 'https://github.com/topics'\n",
    "    response = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topics_url))\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7272ac-50f9-4922-abb2-985375baf2fc",
   "metadata": {},
   "source": [
    "This function takes the URL of a specific topic (e.g., \"Awesome Lists\") and returns its HTML document, which contains repository details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "65ae7e2c-94d1-4429-a5c8-9b5e0220526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    response = requests.get(topic_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to load page {}'.format(topic_url))\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    return topic_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31103b-3f05-4ef4-a661-36e02bb6d13a",
   "metadata": {},
   "source": [
    "1. Combines titles, descriptions, and URLs into a single pandas DataFrame.\n",
    "2. This DataFrame is later used to scrape repositories for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4b3daf8-bfa9-4fb7-a635-71bfd7de765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics():\n",
    "    doc = get_topics_page()   \n",
    "    \n",
    "    titles = get_topic_titles(doc)\n",
    "    descs = get_topic_descs(doc)\n",
    "    urls = get_topic_urls(doc)\n",
    "    \n",
    "    topics_dict = {\n",
    "        'title': titles,\n",
    "        'description': descs,\n",
    "        'url': urls\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b63db-4e2f-4aff-a635-d43b7cc780b6",
   "metadata": {},
   "source": [
    "Extracts repository information from one HTML block:\n",
    "\n",
    "1. Repository owner (username)\n",
    "2. Repository name\n",
    "3. Repository URL\n",
    "4. Number of stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "424f2df8-bcc2-4d72-bd5c-3b4d320a4909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info(h3_tag, star_tag):\n",
    "    # returns all the required info about a repository\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = base_url + a_tags[1]['href']\n",
    "    stars = parse_star_count(star_tag.text.strip())\n",
    "    return username, repo_name, stars, repo_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d40b2f-1031-435a-ad69-938939ba02eb",
   "metadata": {},
   "source": [
    "1. Takes a topic page and extracts all repositories listed under it\n",
    "2. Returns a DataFrame with columns: username, repo_name, stars, and repo_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ecf8554d-073f-4833-b6b6-4c061430450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repos(topic_doc):\n",
    "    #get h3 tags containing repo title,repo url and username\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3',{'class': h3_selection_class})\n",
    "    \n",
    "    #get star tags\n",
    "    star_tags = topic_doc.find_all('span', {'class': 'Counter js-social-count'})\n",
    "    \n",
    "    #get repo info\n",
    "    topic_repos_dict = {\n",
    "        'username': [],\n",
    "        'repo_name': [],\n",
    "        'stars': [],\n",
    "        'repo_url': []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i], star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "    \n",
    "    return pd.DataFrame(topic_repos_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99792693-28cb-43f4-96f4-ffd808f27e0e",
   "metadata": {},
   "source": [
    "Scrapes all repositories from a single topic and saves them to a CSV file.\n",
    "If the file already exists, it skips to avoid duplicate downloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cae323db-9678-4c25-81ef-630d7575bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic(topic_url,path):\n",
    "    #if error occurs no need to download the existing files all over again\n",
    "    #fname = topic_name + '.csv'\n",
    "    if os.path.exists(path):\n",
    "        print(\"The file {} already exists.Skipping...\".format(path))\n",
    "        return\n",
    "        \n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path , index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd48d62d-1c41-40a9-ab6c-632d6f6d8ddc",
   "metadata": {},
   "source": [
    "## Putting all together\n",
    "\n",
    "- list of topics\n",
    "- create csv file for scraped topics page\n",
    "- function to put them together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a040f7-5652-4306-9c92-788fe1ca77ea",
   "metadata": {},
   "source": [
    "This is the main function.\n",
    "\n",
    "1. Gets all topics (title, description, url).\n",
    "2. Creates a data/ folder.\n",
    "3. Iterates through each topic and scrapes its repositories into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "829b089f-b347-4fc3-98cc-6017e101f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    print('Scraping list of topics...')\n",
    "    topics_df = get_topics()  \n",
    "    \n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    for index, row in topics_df.iterrows():\n",
    "        print('Scraping top repositories for \"{}\"...'.format(row['title']))\n",
    "        scrape_topic(row['url'], 'data/{}.csv'.format(row['title']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ac6ba-65a3-4851-8fc1-16eae467738a",
   "metadata": {},
   "source": [
    "Let's run it to scrape the top repos for all the topics on the first page of\n",
    "https://github.com/topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "72c41303-6e6d-4d32-8a4a-dc43767d9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping list of topics...\n",
      "Scraping top repositories for \"Awesome Lists\"...\n",
      "The file data/Awesome Lists.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Chrome\"...\n",
      "The file data/Chrome.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Code quality\"...\n",
      "The file data/Code quality.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Compiler\"...\n",
      "The file data/Compiler.csv already exists.Skipping...\n",
      "Scraping top repositories for \"CSS\"...\n",
      "The file data/CSS.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Database\"...\n",
      "The file data/Database.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Front end\"...\n",
      "The file data/Front end.csv already exists.Skipping...\n",
      "Scraping top repositories for \"JavaScript\"...\n",
      "The file data/JavaScript.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Node.js\"...\n",
      "The file data/Node.js.csv already exists.Skipping...\n",
      "Scraping top repositories for \"npm\"...\n",
      "The file data/npm.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Project management\"...\n",
      "The file data/Project management.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Python\"...\n",
      "The file data/Python.csv already exists.Skipping...\n",
      "Scraping top repositories for \"React\"...\n",
      "The file data/React.csv already exists.Skipping...\n",
      "Scraping top repositories for \"React Native\"...\n",
      "The file data/React Native.csv already exists.Skipping...\n",
      "Scraping top repositories for \"Scala\"...\n",
      "The file data/Scala.csv already exists.Skipping...\n",
      "Scraping top repositories for \"TypeScript\"...\n",
      "The file data/TypeScript.csv already exists.Skipping...\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb18562-aff1-4166-90ac-89ce16e0de95",
   "metadata": {},
   "source": [
    "## Are CSVs created properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "275756fb-22bf-4f8f-87ba-97766190c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and display a CSV using pandas\n",
    "df = pd.read_csv(\"frontend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a582f351-c16d-4616-966c-6eabf27769be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>stars</th>\n",
       "      <th>repo_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook</td>\n",
       "      <td>react</td>\n",
       "      <td>239000</td>\n",
       "      <td>https://github.com/facebook/react</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vuejs</td>\n",
       "      <td>vue</td>\n",
       "      <td>210000</td>\n",
       "      <td>https://github.com/vuejs/vue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vitejs</td>\n",
       "      <td>vite</td>\n",
       "      <td>75500</td>\n",
       "      <td>https://github.com/vitejs/vite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thedaviddias</td>\n",
       "      <td>Front-End-Checklist</td>\n",
       "      <td>71400</td>\n",
       "      <td>https://github.com/thedaviddias/Front-End-Chec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ionic-team</td>\n",
       "      <td>ionic-framework</td>\n",
       "      <td>52100</td>\n",
       "      <td>https://github.com/ionic-team/ionic-framework</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       username            repo_name   stars  \\\n",
       "0      facebook                react  239000   \n",
       "1         vuejs                  vue  210000   \n",
       "2        vitejs                 vite   75500   \n",
       "3  thedaviddias  Front-End-Checklist   71400   \n",
       "4    ionic-team      ionic-framework   52100   \n",
       "\n",
       "                                            repo_url  \n",
       "0                  https://github.com/facebook/react  \n",
       "1                       https://github.com/vuejs/vue  \n",
       "2                     https://github.com/vitejs/vite  \n",
       "3  https://github.com/thedaviddias/Front-End-Chec...  \n",
       "4      https://github.com/ionic-team/ionic-framework  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482fecd8-d415-47ed-96c8-70a7ee3bfa2d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this project, we successfully scraped the **GitHub Topics page** and extracted key details about the top repositories for each topic. The notebook automated the following steps:\n",
    "\n",
    "- Extracted a list of GitHub topics with titles, descriptions, and URLs.  \n",
    "- Scraped repository details such as **repository name, username, stars, and URL** for each topic.  \n",
    "- Saved the data into **CSV files**, one per topic, for easy analysis.  \n",
    "\n",
    "### Key Outcomes\n",
    "- Automated data collection from GitHub topics.  \n",
    "- Created structured datasets for analysis and exploration.  \n",
    "- Built a reproducible workflow using **requests, BeautifulSoup, and pandas**.  \n",
    "\n",
    "### Next Steps\n",
    "- Extend scraping to capture additional metadata (forks, issues, last updated).  \n",
    "- Build a **visual dashboard** to compare repositories across topics.  \n",
    "- Use this dataset for further **data analysis or machine learning tasks** such as identifying trending repositories.  \n",
    "\n",
    "This marks the completion of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6251a-d07d-43fc-8e2e-4d4c4c047c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f8234-ba25-48a9-9500-c3397b7fdbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
